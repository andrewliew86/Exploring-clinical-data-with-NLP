{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting data from ClinicalTrials.gov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First get the clinical trial data into a dataframe\n",
    "# We use pytrials, a Python wrapper around the clinicaltrials.gov API.\n",
    "from pytrials.client import ClinicalTrials\n",
    "import pandas as pd\n",
    "\n",
    "# You create an instance of the ClinicalTrials() object \n",
    "ct = ClinicalTrials()\n",
    "\n",
    "# Here is a list of the fields that would be returned in your results\n",
    "fields = [\"NCTId\",\n",
    "          \"PrimaryCompletionDate\",\n",
    "          \"BriefSummary\", \n",
    "          \"BriefTitle\",\n",
    "          \"ResponsiblePartyInvestigatorAffiliation\",\n",
    "          \"ResponsiblePartyInvestigatorFullName\",\n",
    "          \"PrimaryOutcomeDescription\",\n",
    "          \"Phase\",\n",
    "          \"Condition\",\n",
    "          \"ConditionMeshTerm\",\n",
    "          \"LocationCountry\"\n",
    "            ]\n",
    "\n",
    "# Note, the maximum rows that can be returned is only 1000!\n",
    "data = ct.get_study_fields(\"Coronavirus+COVID\", fields, max_studies=1000, fmt='csv')\n",
    "\n",
    "# Convert to a dataframe and save as a csv file\n",
    "clinical_trials = pd.DataFrame.from_records(data[1:], columns=data[0])\n",
    "clinical_trials.to_csv(\"clinical_trials_nlp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2014 unique tokens: ['collection', 'new', 'outbreak', 'sample', 'south']...)\n"
     ]
    }
   ],
   "source": [
    "# see: https://towardsdatascience.com/building-a-topic-modeling-pipeline-with-spacy-and-gensim-c5dc03ffc619\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Gensim libraries\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import string  # For punctuation removal\n",
    "\n",
    "# Add custom stop words\n",
    "sw_nltk = stopwords.words('english')\n",
    "sw_nltk.extend(['trial', \n",
    "                \"covid\", \n",
    "                \"covid-19\", \n",
    "                \"sars-cov-2\",\n",
    "                \"coronavirus\",\n",
    "                \"study\",\n",
    "                \"infection\",\n",
    "                \"s\"])\n",
    "\n",
    "# Create a lemmatizer object\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    \"\"\"Preprocess text in dataframe column (stopword removal, lowercase, punctuation removal[Note: no removal of / or -])\"\"\"\n",
    "    # First split the text based on whitespace\n",
    "    words = [word for word in text.split()]\n",
    "     # Setup custom removal of punctuation (i.e. remove all but keep hyphens and backlash as these are important in scientific studies)\n",
    "    remove = string.punctuation\n",
    "    remove = remove.replace(\"-\", \"\")  # don't remove hyphens\n",
    "    remove = remove.replace(\"/\", \"\")  # don't remove backslash\n",
    "    pattern = r\"[{}]\".format(remove)  # create the pattern    \n",
    "    words = [re.sub(pattern, \"\", w) for w in words]\n",
    "    #lemmatize words and remove stopwords\n",
    "    words = [lemmatizer.lemmatize(word.lower()) for word in words if word.lower() not in sw_nltk]\n",
    "    return words\n",
    "\n",
    "\n",
    "# Read clinical trial data\n",
    "df = pd.read_csv('clinical_trials_nlp.csv')\n",
    "\n",
    "    \n",
    "# Apply the preprocess function to the 'BriefSummary' column and return as a new column\n",
    "df[\"Summary_tokens\"] = df['BriefTitle'].apply(lambda x: preprocess(x))\n",
    "# Create a list of documents from the column for preprocessing\n",
    "doc_list = df['Summary_tokens'].to_list()\n",
    "\n",
    "# Map word IDs to words.\n",
    "words = gensim.corpora.Dictionary(doc_list)\n",
    "\n",
    "# Turns each document into a bag of words.\n",
    "corpus = [words.doc2bow(doc) for doc in doc_list]\n",
    "\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\n",
      "0.043*\"disease\" + 0.036*\"2019\" + 0.025*\"patient\" + 0.016*\"therapy\" + 0.010*\"effect\" + 0.010*\"treatment\" + 0.010*\"safety\" + 0.010*\"inhalation\" + 0.010*\"cell\" + 0.010*\"evaluation\"\n",
      "topic 1:\n",
      "0.039*\"treatment\" + 0.031*\"convalescent\" + 0.030*\"plasma\" + 0.025*\"disease\" + 0.019*\"patient\" + 0.018*\"care\" + 0.013*\"safety\" + 0.013*\"2019\" + 0.012*\"clinical\" + 0.012*\"efficacy\"\n",
      "topic 2:\n",
      "0.048*\"patient\" + 0.047*\"disease\" + 0.035*\"efficacy\" + 0.032*\"safety\" + 0.032*\"evaluate\" + 0.030*\"2019\" + 0.022*\"severe\" + 0.021*\"hospitalized\" + 0.012*\"treatment\" + 0.012*\"participant\"\n",
      "topic 3:\n",
      "0.028*\"patient\" + 0.015*\"virus\" + 0.014*\"corona\" + 0.014*\"healthcare\" + 0.013*\"pneumonia\" + 0.010*\"response\" + 0.010*\"disease\" + 0.009*\"severe\" + 0.008*\"-\" + 0.008*\"worker\"\n",
      "topic 4:\n",
      "0.061*\"patient\" + 0.017*\"adult\" + 0.016*\"therapy\" + 0.013*\"vaccine\" + 0.012*\"impact\" + 0.011*\"disease\" + 0.011*\"safety\" + 0.011*\"clinical\" + 0.010*\"novel\" + 0.009*\"hospitalized\"\n",
      "topic 5:\n",
      "0.055*\"patient\" + 0.022*\"treatment\" + 0.017*\"clinical\" + 0.015*\"disease\" + 0.011*\"severe\" + 0.011*\"hydroxychloroquine\" + 0.010*\"randomized\" + 0.009*\"controlled\" + 0.008*\"high\" + 0.007*\"prophylaxis\"\n",
      "topic 6:\n",
      "0.020*\"2\" + 0.020*\"\" + 0.018*\"acute\" + 0.016*\"patient\" + 0.015*\"vaccine\" + 0.013*\"outcome\" + 0.013*\"safety\" + 0.012*\"respiratory\" + 0.011*\"syndrome\" + 0.009*\"severe\"\n",
      "topic 7:\n",
      "0.020*\"disease\" + 0.019*\"safety\" + 0.016*\"efficacy\" + 0.015*\"patient\" + 0.014*\"moderate\" + 0.012*\"mild\" + 0.011*\"19\" + 0.009*\"pandemic\" + 0.008*\"treatment\" + 0.008*\"2019\"\n",
      "topic 8:\n",
      "0.037*\"vaccine\" + 0.025*\"novel\" + 0.025*\"recombinant\" + 0.024*\"clinical\" + 0.018*\"phase\" + 0.018*\"disease\" + 0.017*\"adult\" + 0.016*\"patient\" + 0.014*\"pneumonia\" + 0.014*\"cell\"\n",
      "topic 9:\n",
      "0.040*\"respiratory\" + 0.037*\"acute\" + 0.034*\"patient\" + 0.033*\"syndrome\" + 0.030*\"severe\" + 0.021*\"treatment\" + 0.020*\"disease\" + 0.013*\"prevention\" + 0.013*\"2\" + 0.011*\"distress\"\n"
     ]
    }
   ],
   "source": [
    "# LDA model tips here: https://towardsdatascience.com/6-tips-to-optimize-an-nlp-topic-model-for-interpretability-20742f3047e2\n",
    "# also here: https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Print out the topics and their scores from the LDA model\n",
    "for i, v in lda_model.print_topics(num_words=10):\n",
    "    print(\"topic {}:\".format(i))\n",
    "    print(v)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0:\n",
      "0.010*\"disease\" + 0.010*\"2019\" + 0.009*\"cancer\" + 0.008*\"patient\" + 0.006*\"therapy\" + 0.006*\"inhalation\" + 0.005*\"effect\" + 0.005*\"evaluation\" + 0.005*\"vaccination\" + 0.005*\"treatment\"\n",
      "topic 1:\n",
      "0.009*\"stem\" + 0.007*\"cell\" + 0.007*\"safety\" + 0.007*\"mesenchymal\" + 0.007*\"patient\" + 0.007*\"care\" + 0.007*\"covid19\" + 0.007*\"treatment\" + 0.006*\"monitoring\" + 0.006*\"efficacy\"\n",
      "topic 2:\n",
      "0.015*\"convalescent\" + 0.014*\"plasma\" + 0.011*\"disease\" + 0.011*\"treatment\" + 0.008*\"patient\" + 0.008*\"efficacy\" + 0.008*\"safety\" + 0.008*\"outpatient\" + 0.008*\"severe\" + 0.008*\"evaluate\"\n",
      "topic 3:\n",
      "0.006*\"patient\" + 0.005*\"safety\" + 0.005*\"telerehabilitation\" + 0.005*\"icu\" + 0.004*\"severity\" + 0.004*\"cohort\" + 0.004*\"corona\" + 0.004*\"pneumonia\" + 0.004*\"protect\" + 0.004*\"people\"\n",
      "topic 4:\n",
      "0.010*\"patient\" + 0.008*\"therapy\" + 0.006*\"hospitalized\" + 0.005*\"hydroxychloroquine\" + 0.005*\"disease\" + 0.005*\"impact\" + 0.004*\"efficacy\" + 0.004*\"diabetes\" + 0.004*\"covid19\" + 0.004*\"2\"\n",
      "topic 5:\n",
      "0.009*\"patient\" + 0.009*\"treatment\" + 0.008*\"critically\" + 0.008*\"clinical\" + 0.007*\"ill\" + 0.006*\"severe\" + 0.006*\"prophylaxis\" + 0.005*\"respiratory\" + 0.005*\"2\" + 0.005*\"disease\"\n",
      "topic 6:\n",
      "0.007*\"acute\" + 0.007*\"respiratory\" + 0.006*\"vaccine\" + 0.006*\"outcome\" + 0.006*\"2\" + 0.005*\"syndrome\" + 0.005*\"patient\" + 0.005*\"long\" + 0.005*\"2019\" + 0.005*\"safety\"\n",
      "topic 7:\n",
      "0.006*\"disease\" + 0.005*\"efficacy\" + 0.005*\"patient\" + 0.005*\"safety\" + 0.005*\"2019\" + 0.004*\"pneumonia\" + 0.004*\"19\" + 0.004*\"investigating\" + 0.004*\"treatment\" + 0.004*\"mild\"\n",
      "topic 8:\n",
      "0.011*\"vaccine\" + 0.011*\"clinical\" + 0.009*\"recombinant\" + 0.009*\"adult\" + 0.009*\"moderate\" + 0.008*\"phase\" + 0.008*\"novel\" + 0.007*\"mild\" + 0.007*\"patient\" + 0.007*\"disease\"\n",
      "topic 9:\n",
      "0.009*\"treatment\" + 0.009*\"disease\" + 0.008*\"patient\" + 0.008*\"severe\" + 0.007*\"respiratory\" + 0.007*\"nitazoxanide\" + 0.007*\"2019\" + 0.007*\"acute\" + 0.006*\"prevention\" + 0.006*\"evaluate\"\n"
     ]
    }
   ],
   "source": [
    "# Apart from the bag of words model, lets also perform tf-idf vectorization and use the results for LDA modelling for comparrison\n",
    "tfidf = gensim.models.TfidfModel(corpus)\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus_tfidf,\n",
    "                                           id2word=words,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=2,\n",
    "                                           update_every=1,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "# Print out the topics and their scores from the LDA model\n",
    "for i, v in lda_model.print_topics(num_words=10):\n",
    "    print(\"topic {}:\".format(i))\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyLDAvis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-33f74131de35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# pyLDavis to visualize the topics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# pyLDavis is a wrapper aroud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpyLDAvis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgensim_models\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgensimvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#import pyLDAvis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyLDAvis'"
     ]
    }
   ],
   "source": [
    "# pyLDavis to visualize the topics\n",
    "# pyLDavis is a wrapper aroud\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "#import pyLDAvis\n",
    "#import pyLDAvis.gensim_models\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "vis = pyLDAvis.gensim.prepare(topic_model=lda_model, \n",
    "                              corpus=corpus_tfidf, \n",
    "                              dictionary=words)\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m pip install -U pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a39c0e205df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conda'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'install -c conda-forge pyLDAvis'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2305\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2307\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2308\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<C:\\Users\\Andrew\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\decorator.py:decorator-gen-108>\u001b[0m in \u001b[0;36mconda\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\IPython\\core\\magics\\packaging.py\u001b[0m in \u001b[0;36mconda\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \"\"\"\n\u001b[0;32m     79\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_is_conda_environment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             raise ValueError(\"The python kernel does not appear to be a conda environment.  \"\n\u001b[0m\u001b[0;32m     81\u001b[0m                              \"Please use ``%pip install`` instead.\")\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The python kernel does not appear to be a conda environment.  Please use ``%pip install`` instead."
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "     active environment : NLP\n",
      "    active env location : C:\\Users\\Andrew\\Anaconda3\\envs\\NLP\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\Andrew\\.condarc\n",
      " populated config files : C:\\Users\\Andrew\\.condarc\n",
      "          conda version : 4.9.2\n",
      "    conda-build version : 3.18.10\n",
      "         python version : 3.6.9.final.0\n",
      "       virtual packages : __cuda=10.2=0\n",
      "                          __win=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : C:\\Users\\Andrew\\Anaconda3  (writable)\n",
      "           channel URLs : https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\Users\\Andrew\\Anaconda3\\pkgs\n",
      "                          C:\\Users\\Andrew\\.conda\\pkgs\n",
      "                          C:\\Users\\Andrew\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\Andrew\\Anaconda3\\envs\n",
      "                          C:\\Users\\Andrew\\.conda\\envs\n",
      "                          C:\\Users\\Andrew\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.9.2 requests/2.25.1 CPython/3.6.9 Windows/10 Windows/10.0.19041\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 32-bit",
   "language": "python",
   "name": "python37232bitf5e6d4f517554bacbd8f864bbc2e2e11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
